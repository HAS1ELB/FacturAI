#!/usr/bin/env python3
"""
Pipeline de pr√©traitement complet pour les factures
Int√®gre PDF ‚Üí Images ‚Üí Am√©lioration ‚Üí Validation qualit√©
"""

import os
import sys
import json
import argparse
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import concurrent.futures
from datetime import datetime
import pandas as pd

# Imports des modules personnalis√©s
from preprocessing.pdf_to_image import convert_from_path
from image_enhancement import InvoiceImageEnhancer

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('preprocessing.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class InvoicePreprocessingPipeline:
    """Pipeline complet de pr√©traitement des factures"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialise la pipeline de pr√©traitement
        
        Args:
            config: Configuration personnalis√©e (optionnel)
        """
        self.config = config or self._get_default_config()
        self.enhancer = InvoiceImageEnhancer()
        
        # Cr√©ation des dossiers n√©cessaires
        self._setup_directories()
        
        # Statistiques de traitement
        self.processing_stats = {
            'total_files': 0,
            'successful': 0,
            'failed': 0,
            'start_time': None,
            'end_time': None,
            'failed_files': []
        }
        
    def _get_default_config(self) -> Dict[str, Any]:
        """Configuration par d√©faut de la pipeline"""
        return {
            'input_pdf_dir': 'Data/ids_factures',
            'temp_images_dir': 'Data/temp_images',
            'output_images_dir': 'Data/processed_images',
            'quality_reports_dir': 'Data/quality_reports',
            'backup_dir': 'Data/backup_originals',
            'pdf_conversion': {
                'dpi': 300,
                'format': 'PNG',
                'poppler_path': r"C:/tools/poppler/Library/bin"
            },
            'parallel_processing': True,
            'max_workers': 4,
            'quality_threshold': 60.0,
            'backup_originals': True,
            'generate_reports': True
        }
    
    def _setup_directories(self):
        """Cr√©e tous les dossiers n√©cessaires"""
        directories = [
            self.config['temp_images_dir'],
            self.config['output_images_dir'],
            self.config['quality_reports_dir'],
            self.config['backup_dir']
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            logger.info(f"Dossier pr√©par√©: {directory}")
    
    def run_full_pipeline(self) -> Dict[str, Any]:
        """
        Ex√©cute la pipeline compl√®te de pr√©traitement
        
        Returns:
            Dict: R√©sultats du traitement avec statistiques
        """
        logger.info("üöÄ D√©but de la pipeline de pr√©traitement compl√®te")
        self.processing_stats['start_time'] = datetime.now()
        
        try:
            # √âtape 1: Conversion PDF ‚Üí Images
            pdf_files = self._get_pdf_files()
            if not pdf_files:
                logger.warning("Aucun fichier PDF trouv√© dans le dossier d'entr√©e")
                return self.processing_stats
            
            self.processing_stats['total_files'] = len(pdf_files)
            logger.info(f"üìÅ {len(pdf_files)} fichiers PDF trouv√©s")
            
            # √âtape 2: Conversion en images
            extracted_images = self._convert_pdfs_to_images(pdf_files)
            
            # √âtape 3: Am√©lioration des images
            enhanced_images = self._enhance_images(extracted_images)
            
            # √âtape 4: Validation qualit√©
            quality_results = self._validate_quality(enhanced_images)
            
            # √âtape 5: G√©n√©ration des rapports
            if self.config['generate_reports']:
                self._generate_processing_report(quality_results)
            
            # √âtape 6: Nettoyage des fichiers temporaires
            self._cleanup_temp_files()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur dans la pipeline: {str(e)}")
            self.processing_stats['failed'] = self.processing_stats['total_files']
        
        finally:
            self.processing_stats['end_time'] = datetime.now()
            self._log_final_statistics()
        
        return self.processing_stats
    
    def _get_pdf_files(self) -> List[str]:
        """R√©cup√®re la liste des fichiers PDF √† traiter"""
        input_dir = Path(self.config['input_pdf_dir'])
        
        if not input_dir.exists():
            logger.error(f"‚ùå Dossier d'entr√©e non trouv√©: {input_dir}")
            return []
        
        pdf_files = list(input_dir.glob('*.pdf'))
        return [str(pdf_file) for pdf_file in pdf_files]
    
    def _convert_pdfs_to_images(self, pdf_files: List[str]) -> List[str]:
        """Convertit les PDFs en images"""
        logger.info("üìÑ D√©but de la conversion PDF ‚Üí Images")
        
        extracted_images = []
        
        for pdf_file in pdf_files:
            try:
                # Sauvegarde de l'original si demand√©
                if self.config['backup_originals']:
                    self._backup_original_file(pdf_file)
                
                # Conversion PDF ‚Üí Images
                images = convert_from_path(
                    pdf_file,
                    dpi=self.config['pdf_conversion']['dpi'],
                    poppler_path=self.config['pdf_conversion'].get('poppler_path')
                )
                
                # Sauvegarde des images extraites
                for i, image in enumerate(images):
                    base_name = Path(pdf_file).stem
                    image_filename = f"{base_name}_page{i+1}.png"
                    image_path = os.path.join(self.config['temp_images_dir'], image_filename)
                    
                    image.save(image_path, 'PNG', dpi=(300, 300))
                    extracted_images.append(image_path)
                    
                    logger.info(f"‚úÖ Image extraite: {image_filename}")
                
                self.processing_stats['successful'] += 1
                
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de la conversion de {pdf_file}: {str(e)}")
                self.processing_stats['failed'] += 1
                self.processing_stats['failed_files'].append(pdf_file)
        
        logger.info(f"üìÑ Conversion termin√©e: {len(extracted_images)} images extraites")
        return extracted_images
    
    def _enhance_images(self, image_paths: List[str]) -> List[str]:
        """Am√©liore la qualit√© des images extraites"""
        logger.info("üé® D√©but de l'am√©lioration des images")
        
        enhanced_images = []
        
        if self.config['parallel_processing']:
            # Traitement parall√®le
            with concurrent.futures.ThreadPoolExecutor(
                max_workers=self.config['max_workers']
            ) as executor:
                
                future_to_path = {
                    executor.submit(self._enhance_single_image, img_path): img_path 
                    for img_path in image_paths
                }
                
                for future in concurrent.futures.as_completed(future_to_path):
                    img_path = future_to_path[future]
                    try:
                        enhanced_path = future.result()
                        if enhanced_path:
                            enhanced_images.append(enhanced_path)
                    except Exception as e:
                        logger.error(f"‚ùå Erreur am√©lioration {img_path}: {str(e)}")
        else:
            # Traitement s√©quentiel
            for img_path in image_paths:
                enhanced_path = self._enhance_single_image(img_path)
                if enhanced_path:
                    enhanced_images.append(enhanced_path)
        
        logger.info(f"üé® Am√©lioration termin√©e: {len(enhanced_images)} images am√©lior√©es")
        return enhanced_images
    
    def _enhance_single_image(self, image_path: str) -> Optional[str]:
        """Am√©liore une seule image"""
        try:
            # G√©n√©ration du chemin de sortie
            base_name = Path(image_path).stem
            output_path = os.path.join(
                self.config['output_images_dir'], 
                f"enhanced_{base_name}.png"
            )
            
            # Am√©lioration de l'image
            self.enhancer.enhance_invoice_image(image_path, output_path)
            
            logger.info(f"‚úÖ Image am√©lior√©e: {base_name}")
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå Erreur am√©lioration {image_path}: {str(e)}")
            return None
    
    def _validate_quality(self, enhanced_images: List[str]) -> List[Dict[str, Any]]:
        """Valide la qualit√© des images am√©lior√©es"""
        logger.info("üîç D√©but de la validation qualit√©")
        
        quality_results = []
        
        for image_path in enhanced_images:
            try:
                # Chargement et analyse de l'image
                import cv2
                image = cv2.imread(image_path)
                
                if image is not None:
                    quality_metrics = self.enhancer.analyze_image_quality(image)
                    
                    result = {
                        'image_path': image_path,
                        'filename': Path(image_path).name,
                        'metrics': quality_metrics,
                        'quality_pass': quality_metrics['quality_score'] >= self.config['quality_threshold']
                    }
                    
                    quality_results.append(result)
                    
                    # Log du r√©sultat
                    status = "‚úÖ PASS" if result['quality_pass'] else "‚ö†Ô∏è BELOW_THRESHOLD"
                    score = quality_metrics['quality_score']
                    logger.info(f"{status} - {result['filename']}: Score = {score:.1f}")
                
            except Exception as e:
                logger.error(f"‚ùå Erreur validation {image_path}: {str(e)}")
        
        # Statistiques de qualit√©
        passed = sum(1 for r in quality_results if r['quality_pass'])
        total = len(quality_results)
        logger.info(f"üîç Validation termin√©e: {passed}/{total} images passent le seuil qualit√©")
        
        return quality_results
    
    def _generate_processing_report(self, quality_results: List[Dict[str, Any]]):
        """G√©n√®re un rapport d√©taill√© du traitement"""
        logger.info("üìä G√©n√©ration du rapport de traitement")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Rapport JSON d√©taill√©
        json_report_path = os.path.join(
            self.config['quality_reports_dir'], 
            f"processing_report_{timestamp}.json"
        )
        
        full_report = {
            'processing_info': {
                'timestamp': timestamp,
                'config': self.config,
                'stats': self.processing_stats
            },
            'quality_results': quality_results
        }
        
        with open(json_report_path, 'w', encoding='utf-8') as f:
            json.dump(full_report, f, indent=2, ensure_ascii=False, default=str)
        
        # Rapport CSV pour analyse
        csv_report_path = os.path.join(
            self.config['quality_reports_dir'], 
            f"quality_metrics_{timestamp}.csv"
        )
        
        if quality_results:
            df_data = []
            for result in quality_results:
                row = {
                    'filename': result['filename'],
                    'quality_pass': result['quality_pass'],
                    **result['metrics']
                }
                df_data.append(row)
            
            df = pd.DataFrame(df_data)
            df.to_csv(csv_report_path, index=False)
        
        # Rapport HTML visuel
        self._generate_html_report(quality_results, timestamp)
        
        logger.info(f"üìä Rapports g√©n√©r√©s:")
        logger.info(f"   - JSON: {json_report_path}")
        logger.info(f"   - CSV: {csv_report_path}")
    
    def _generate_html_report(self, quality_results: List[Dict[str, Any]], timestamp: str):
        """G√©n√®re un rapport HTML visuel"""
        html_report_path = os.path.join(
            self.config['quality_reports_dir'], 
            f"visual_report_{timestamp}.html"
        )
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Rapport de Traitement - Factures</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ background: #2e8b57; color: white; padding: 10px; text-align: center; }}
                .stats {{ display: flex; justify-content: space-around; margin: 20px 0; }}
                .stat-box {{ background: #f0f0f0; padding: 15px; border-radius: 5px; text-align: center; }}
                .quality-table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
                .quality-table th, .quality-table td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                .quality-table th {{ background-color: #f2f2f2; }}
                .pass {{ background-color: #d4edda; }}
                .fail {{ background-color: #f8d7da; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>üîç Rapport de Traitement des Factures</h1>
                <p>G√©n√©r√© le: {datetime.now().strftime('%d/%m/%Y √† %H:%M:%S')}</p>
            </div>
            
            <div class="stats">
                <div class="stat-box">
                    <h3>üìÑ Total Trait√©s</h3>
                    <p style="font-size: 24px; color: #2e8b57;">{self.processing_stats['total_files']}</p>
                </div>
                <div class="stat-box">
                    <h3>‚úÖ Succ√®s</h3>
                    <p style="font-size: 24px; color: #28a745;">{self.processing_stats['successful']}</p>
                </div>
                <div class="stat-box">
                    <h3>‚ùå √âchecs</h3>
                    <p style="font-size: 24px; color: #dc3545;">{self.processing_stats['failed']}</p>
                </div>
                <div class="stat-box">
                    <h3>üéØ Qualit√© OK</h3>
                    <p style="font-size: 24px; color: #007bff;">{sum(1 for r in quality_results if r['quality_pass'])}</p>
                </div>
            </div>
            
            <table class="quality-table">
                <thead>
                    <tr>
                        <th>Fichier</th>
                        <th>Score Qualit√©</th>
                        <th>Nettet√©</th>
                        <th>Contraste</th>
                        <th>Luminosit√©</th>
                        <th>Statut</th>
                    </tr>
                </thead>
                <tbody>
        """
        
        for result in quality_results:
            metrics = result['metrics']
            status_class = 'pass' if result['quality_pass'] else 'fail'
            status_text = 'PASS ‚úÖ' if result['quality_pass'] else 'FAIL ‚ùå'
            
            html_content += f"""
                    <tr class="{status_class}">
                        <td>{result['filename']}</td>
                        <td>{metrics['quality_score']:.1f}</td>
                        <td>{metrics['sharpness']:.1f}</td>
                        <td>{metrics['contrast']:.1f}</td>
                        <td>{metrics['brightness']:.1f}</td>
                        <td>{status_text}</td>
                    </tr>
            """
        
        html_content += """
                </tbody>
            </table>
        </body>
        </html>
        """
        
        with open(html_report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        logger.info(f"   - HTML: {html_report_path}")
    
    def _backup_original_file(self, pdf_file: str):
        """Sauvegarde le fichier original"""
        try:
            import shutil
            backup_path = os.path.join(
                self.config['backup_dir'], 
                Path(pdf_file).name
            )
            shutil.copy2(pdf_file, backup_path)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur sauvegarde {pdf_file}: {str(e)}")
    
    def _cleanup_temp_files(self):
        """Nettoie les fichiers temporaires"""
        try:
            import shutil
            temp_dir = Path(self.config['temp_images_dir'])
            if temp_dir.exists():
                shutil.rmtree(temp_dir)
                os.makedirs(temp_dir, exist_ok=True)
                logger.info("üßπ Fichiers temporaires nettoy√©s")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur nettoyage fichiers temporaires: {str(e)}")
    
    def _log_final_statistics(self):
        """Affiche les statistiques finales"""
        duration = (self.processing_stats['end_time'] - self.processing_stats['start_time']).total_seconds()
        
        logger.info("=" * 60)
        logger.info("üìä STATISTIQUES FINALES DE TRAITEMENT")
        logger.info("=" * 60)
        logger.info(f"‚è±Ô∏è  Dur√©e totale: {duration:.1f} secondes")
        logger.info(f"üìÑ Fichiers trait√©s: {self.processing_stats['total_files']}")
        logger.info(f"‚úÖ Succ√®s: {self.processing_stats['successful']}")
        logger.info(f"‚ùå √âchecs: {self.processing_stats['failed']}")
        
        if self.processing_stats['failed_files']:
            logger.info("‚ùå Fichiers √©chou√©s:")
            for failed_file in self.processing_stats['failed_files']:
                logger.info(f"   - {failed_file}")
        
        logger.info("=" * 60)

def main():
    """Fonction principale avec interface CLI"""
    parser = argparse.ArgumentParser(description='Pipeline de pr√©traitement de factures')
    
    parser.add_argument('--input-dir', default='Data/ids_factures',
                       help='Dossier des PDFs source')
    parser.add_argument('--output-dir', default='Data/processed_images',
                       help='Dossier des images finales')
    parser.add_argument('--dpi', type=int, default=300,
                       help='R√©solution pour la conversion PDF')
    parser.add_argument('--quality-threshold', type=float, default=60.0,
                       help='Seuil de qualit√© minimum')
    parser.add_argument('--parallel', action='store_true', default=True,
                       help='Activation du traitement parall√®le')
    parser.add_argument('--workers', type=int, default=4,
                       help='Nombre de workers pour le traitement parall√®le')
    
    args = parser.parse_args()
    
    # Configuration personnalis√©e
    custom_config = {
        'input_pdf_dir': args.input_dir,
        'output_images_dir': args.output_dir,
        'pdf_conversion': {'dpi': args.dpi},
        'quality_threshold': args.quality_threshold,
        'parallel_processing': args.parallel,
        'max_workers': args.workers
    }
    
    # Lancement de la pipeline
    pipeline = InvoicePreprocessingPipeline(custom_config)
    results = pipeline.run_full_pipeline()
    
    # Affichage du r√©sum√©
    print("\n" + "=" * 50)
    print("üéâ TRAITEMENT TERMIN√â")
    print("=" * 50)
    print(f"‚úÖ {results['successful']} fichiers trait√©s avec succ√®s")
    print(f"‚ùå {results['failed']} fichiers en √©chec")
    print(f"üìä Consultez les rapports dans: Data/quality_reports/")
    print("=" * 50)

if __name__ == "__main__":
    main()
